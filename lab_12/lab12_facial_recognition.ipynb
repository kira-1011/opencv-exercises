{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 12: Facial Recognition & Landmark Detection (OpenCV DNN + Dlib)\n",
        "\n",
        "## Objective\n",
        "To implement face detection, recognition using face embeddings, and facial landmark detection using OpenCV's DNN module and Dlib. This lab provides a foundation for building real-time face-based systems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What is Facial Recognition?\n",
        "\n",
        "**Description**: Facial recognition involves identifying or verifying a person's identity from an image. It often includes face detection, alignment, embedding extraction, and matching.\n",
        "\n",
        "### Key Components:\n",
        "- **Face Detection**: Locating faces in images\n",
        "- **Face Alignment**: Normalizing face orientation\n",
        "- **Feature Extraction**: Creating face embeddings\n",
        "- **Face Matching**: Comparing embeddings for recognition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "### Required Libraries:\n",
        "- **OpenCV** for face detection and image processing\n",
        "- **Dlib** for landmarks and face embeddings\n",
        "- **face_recognition** wrapper for simplified face encoding and comparison\n",
        "\n",
        "### Installation:\n",
        "```bash\n",
        "pip install opencv-python dlib face_recognition imutils numpy\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Try to import face_recognition and dlib\n",
        "try:\n",
        "    import face_recognition\n",
        "    import dlib\n",
        "    print(\"‚úÖ All libraries imported successfully!\")\n",
        "    print(f\"OpenCV version: {cv2.__version__}\")\n",
        "    print(f\"Dlib version: {dlib.version}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please install missing libraries:\")\n",
        "    print(\"pip install face-recognition dlib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Face Detection using OpenCV DNN\n",
        "\n",
        "We'll use OpenCV's DNN module with a pre-trained face detection model for robust face detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_face_detector():\n",
        "    \"\"\"\n",
        "    Load OpenCV DNN face detection model\n",
        "    Using OpenCV's built-in face detection model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Try to use OpenCV's built-in face detector\n",
        "        detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        print(\"‚úÖ Haar Cascade face detector loaded successfully\")\n",
        "        return detector, 'haar'\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading face detector: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def detect_faces_opencv(image, detector, detector_type='haar'):\n",
        "    \"\"\"\n",
        "    Detect faces using OpenCV\n",
        "    \n",
        "    Args:\n",
        "        image: Input image\n",
        "        detector: Face detector object\n",
        "        detector_type: Type of detector ('haar' or 'dnn')\n",
        "    \n",
        "    Returns:\n",
        "        faces: List of face bounding boxes\n",
        "        annotated_image: Image with face boxes drawn\n",
        "    \"\"\"\n",
        "    if detector is None:\n",
        "        return [], image.copy()\n",
        "    \n",
        "    # Convert to grayscale for Haar cascade\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    if detector_type == 'haar':\n",
        "        # Detect faces using Haar cascade\n",
        "        faces = detector.detectMultiScale(\n",
        "            gray,\n",
        "            scaleFactor=1.1,\n",
        "            minNeighbors=5,\n",
        "            minSize=(30, 30)\n",
        "        )\n",
        "    \n",
        "    # Draw bounding boxes\n",
        "    annotated_image = image.copy()\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(annotated_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(annotated_image, 'Face', (x, y - 10), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "    \n",
        "    return faces, annotated_image\n",
        "\n",
        "# Load face detector\n",
        "face_detector, detector_type = load_face_detector()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test face detection on sample images\n",
        "def test_face_detection():\n",
        "    \"\"\"Test face detection on available images\"\"\"\n",
        "    \n",
        "    # List of test images\n",
        "    test_images = [\n",
        "        'images/face.jpeg',\n",
        "        'images/person.jpg',\n",
        "        'images/person_1.jpg',\n",
        "        'images/person_2.jpg'\n",
        "    ]\n",
        "    \n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    for i, img_path in enumerate(test_images):\n",
        "        if os.path.exists(img_path):\n",
        "            # Load image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                \n",
        "                # Detect faces\n",
        "                faces, annotated_img = detect_faces_opencv(img, face_detector, detector_type)\n",
        "                annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
        "                \n",
        "                # Display results\n",
        "                plt.subplot(2, len(test_images), i + 1)\n",
        "                plt.imshow(img_rgb)\n",
        "                plt.title(f'Original: {Path(img_path).name}')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                plt.subplot(2, len(test_images), i + 1 + len(test_images))\n",
        "                plt.imshow(annotated_img_rgb)\n",
        "                plt.title(f'Detected: {len(faces)} face(s)')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                print(f\"‚úÖ {img_path}: {len(faces)} face(s) detected\")\n",
        "            else:\n",
        "                print(f\"‚ùå Could not load {img_path}\")\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {img_path}\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run face detection test\n",
        "test_face_detection()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Facial Landmark Detection with Dlib\n",
        "\n",
        "Facial landmarks help identify key points on the face like eyes, nose, mouth, and jaw contours.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_facial_landmarks(image, face_locations):\n",
        "    \"\"\"\n",
        "    Detect facial landmarks using face_recognition library\n",
        "    \n",
        "    Args:\n",
        "        image: Input image\n",
        "        face_locations: List of face bounding boxes\n",
        "    \n",
        "    Returns:\n",
        "        landmarks_list: List of facial landmarks for each face\n",
        "        annotated_image: Image with landmarks drawn\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert OpenCV format to face_recognition format\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Convert face locations from (x,y,w,h) to (top,right,bottom,left)\n",
        "        face_locations_converted = []\n",
        "        for (x, y, w, h) in face_locations:\n",
        "            face_locations_converted.append((y, x + w, y + h, x))\n",
        "        \n",
        "        # Get facial landmarks\n",
        "        landmarks_list = face_recognition.face_landmarks(rgb_image, face_locations_converted)\n",
        "        \n",
        "        # Draw landmarks on image\n",
        "        annotated_image = image.copy()\n",
        "        \n",
        "        for landmarks in landmarks_list:\n",
        "            # Draw different facial features with different colors\n",
        "            colors = {\n",
        "                'chin': (255, 0, 0),           # Red\n",
        "                'left_eyebrow': (0, 255, 0),   # Green\n",
        "                'right_eyebrow': (0, 255, 0),  # Green\n",
        "                'nose_bridge': (0, 0, 255),    # Blue\n",
        "                'nose_tip': (0, 0, 255),       # Blue\n",
        "                'left_eye': (255, 255, 0),     # Cyan\n",
        "                'right_eye': (255, 255, 0),    # Cyan\n",
        "                'top_lip': (255, 0, 255),      # Magenta\n",
        "                'bottom_lip': (255, 0, 255)    # Magenta\n",
        "            }\n",
        "            \n",
        "            for feature, points in landmarks.items():\n",
        "                color = colors.get(feature, (255, 255, 255))\n",
        "                for point in points:\n",
        "                    cv2.circle(annotated_image, point, 2, color, -1)\n",
        "        \n",
        "        return landmarks_list, annotated_image\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in landmark detection: {e}\")\n",
        "        return [], image.copy()\n",
        "\n",
        "def draw_landmark_connections(image, landmarks_list):\n",
        "    \"\"\"\n",
        "    Draw connections between landmark points to show facial structure\n",
        "    \"\"\"\n",
        "    annotated_image = image.copy()\n",
        "    \n",
        "    for landmarks in landmarks_list:\n",
        "        # Draw connections for facial features\n",
        "        feature_connections = [\n",
        "            ('chin', (255, 0, 0)),\n",
        "            ('left_eyebrow', (0, 255, 0)),\n",
        "            ('right_eyebrow', (0, 255, 0)),\n",
        "            ('left_eye', (255, 255, 0)),\n",
        "            ('right_eye', (255, 255, 0)),\n",
        "            ('top_lip', (255, 0, 255)),\n",
        "            ('bottom_lip', (255, 0, 255))\n",
        "        ]\n",
        "        \n",
        "        for feature, color in feature_connections:\n",
        "            if feature in landmarks:\n",
        "                points = landmarks[feature]\n",
        "                for i in range(len(points) - 1):\n",
        "                    cv2.line(annotated_image, points[i], points[i + 1], color, 1)\n",
        "                \n",
        "                # Close the loop for eyes and lips\n",
        "                if feature in ['left_eye', 'right_eye', 'top_lip', 'bottom_lip']:\n",
        "                    cv2.line(annotated_image, points[-1], points[0], color, 1)\n",
        "    \n",
        "    return annotated_image\n",
        "\n",
        "print(\"‚úÖ Facial landmark detection functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test facial landmark detection\n",
        "def test_landmark_detection():\n",
        "    \"\"\"Test facial landmark detection on sample images\"\"\"\n",
        "    \n",
        "    test_images = [\n",
        "        'images/face.jpeg',\n",
        "        'images/person.jpg'\n",
        "    ]\n",
        "    \n",
        "    for img_path in test_images:\n",
        "        if os.path.exists(img_path):\n",
        "            # Load image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                print(f\"\\nüîç Processing {img_path}...\")\n",
        "                \n",
        "                # First detect faces\n",
        "                faces, _ = detect_faces_opencv(img, face_detector, detector_type)\n",
        "                print(f\"   Found {len(faces)} face(s)\")\n",
        "                \n",
        "                if len(faces) > 0:\n",
        "                    # Detect landmarks\n",
        "                    landmarks_list, landmarks_img = detect_facial_landmarks(img, faces)\n",
        "                    connections_img = draw_landmark_connections(img, landmarks_list)\n",
        "                    \n",
        "                    # Display results\n",
        "                    plt.figure(figsize=(15, 5))\n",
        "                    \n",
        "                    # Original image\n",
        "                    plt.subplot(1, 3, 1)\n",
        "                    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Original Image')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    # Landmarks points\n",
        "                    plt.subplot(1, 3, 2)\n",
        "                    plt.imshow(cv2.cvtColor(landmarks_img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title(f'Facial Landmarks ({len(landmarks_list)} face(s))')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    # Landmark connections\n",
        "                    plt.subplot(1, 3, 3)\n",
        "                    plt.imshow(cv2.cvtColor(connections_img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Landmark Connections')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Print landmark details\n",
        "                    for i, landmarks in enumerate(landmarks_list):\n",
        "                        print(f\"   Face {i+1}: {len(landmarks)} landmark groups detected\")\n",
        "                        for feature, points in landmarks.items():\n",
        "                            print(f\"     - {feature}: {len(points)} points\")\n",
        "                else:\n",
        "                    print(\"   No faces detected for landmark analysis\")\n",
        "            else:\n",
        "                print(f\"‚ùå Could not load {img_path}\")\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {img_path}\")\n",
        "\n",
        "# Run landmark detection test\n",
        "test_landmark_detection()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Face Recognition using Face Embeddings\n",
        "\n",
        "Face recognition involves creating unique embeddings (feature vectors) for each face and comparing them to identify individuals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_face_encodings(image_path, name):\n",
        "    \"\"\"\n",
        "    Create face encodings for a person from their image\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the person's image\n",
        "        name: Name of the person\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with name and encoding\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        \n",
        "        # Get face encodings\n",
        "        encodings = face_recognition.face_encodings(image)\n",
        "        \n",
        "        if len(encodings) > 0:\n",
        "            print(f\"‚úÖ Created encoding for {name} from {image_path}\")\n",
        "            return {\n",
        "                'name': name,\n",
        "                'encoding': encodings[0],  # Take first face found\n",
        "                'image_path': image_path\n",
        "            }\n",
        "        else:\n",
        "            print(f\"‚ùå No face found in {image_path} for {name}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating encoding for {name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def recognize_faces_in_image(image_path, known_encodings, tolerance=0.6):\n",
        "    \"\"\"\n",
        "    Recognize faces in an image by comparing with known encodings\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to image to analyze\n",
        "        known_encodings: List of known face encodings\n",
        "        tolerance: Face matching tolerance (lower = stricter)\n",
        "    \n",
        "    Returns:\n",
        "        Results dictionary with matches and annotated image\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        \n",
        "        # Find face locations and encodings\n",
        "        face_locations = face_recognition.face_locations(image)\n",
        "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
        "        \n",
        "        # Convert to OpenCV format for drawing\n",
        "        cv_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        results = []\n",
        "        \n",
        "        # Compare each found face with known faces\n",
        "        for i, face_encoding in enumerate(face_encodings):\n",
        "            matches = []\n",
        "            distances = []\n",
        "            \n",
        "            for known_face in known_encodings:\n",
        "                if known_face is not None:\n",
        "                    # Compare faces\n",
        "                    match = face_recognition.compare_faces([known_face['encoding']], face_encoding, tolerance=tolerance)\n",
        "                    distance = face_recognition.face_distance([known_face['encoding']], face_encoding)[0]\n",
        "                    \n",
        "                    matches.append(match[0])\n",
        "                    distances.append(distance)\n",
        "            \n",
        "            # Find best match\n",
        "            if any(matches):\n",
        "                best_match_index = distances.index(min(distances))\n",
        "                if matches[best_match_index]:\n",
        "                    name = known_encodings[best_match_index]['name']\n",
        "                    confidence = 1 - distances[best_match_index]\n",
        "                else:\n",
        "                    name = \"Unknown\"\n",
        "                    confidence = 0\n",
        "            else:\n",
        "                name = \"Unknown\"\n",
        "                confidence = 0\n",
        "            \n",
        "            # Draw bounding box and label\n",
        "            top, right, bottom, left = face_locations[i]\n",
        "            \n",
        "            # Choose color based on recognition\n",
        "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "            \n",
        "            # Draw rectangle and label\n",
        "            cv2.rectangle(cv_image, (left, top), (right, bottom), color, 2)\n",
        "            cv2.rectangle(cv_image, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
        "            \n",
        "            # Add text\n",
        "            label = f\"{name} ({confidence:.2f})\" if name != \"Unknown\" else \"Unknown\"\n",
        "            cv2.putText(cv_image, label, (left + 6, bottom - 6), \n",
        "                       cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
        "            \n",
        "            results.append({\n",
        "                'name': name,\n",
        "                'confidence': confidence,\n",
        "                'location': (top, right, bottom, left)\n",
        "            })\n",
        "        \n",
        "        return {\n",
        "            'results': results,\n",
        "            'annotated_image': cv_image,\n",
        "            'total_faces': len(face_locations)\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in face recognition: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Face recognition functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a face recognition system\n",
        "def setup_face_recognition_system():\n",
        "    \"\"\"\n",
        "    Set up a face recognition system with known faces\n",
        "    \"\"\"\n",
        "    print(\"üîß Setting up Face Recognition System...\")\n",
        "    \n",
        "    # Define known people (you can add more)\n",
        "    known_people = [\n",
        "        {'name': 'Person_1', 'image': 'images/person_1.jpg'},\n",
        "        {'name': 'Person_2', 'image': 'images/person_2.jpg'},\n",
        "    ]\n",
        "    \n",
        "    # Create encodings for known people\n",
        "    known_encodings = []\n",
        "    \n",
        "    for person in known_people:\n",
        "        if os.path.exists(person['image']):\n",
        "            encoding = create_face_encodings(person['image'], person['name'])\n",
        "            if encoding is not None:\n",
        "                known_encodings.append(encoding)\n",
        "        else:\n",
        "            print(f\"‚ùå Image not found: {person['image']}\")\n",
        "    \n",
        "    print(f\"‚úÖ Face recognition system ready with {len(known_encodings)} known faces\")\n",
        "    return known_encodings\n",
        "\n",
        "def test_face_recognition():\n",
        "    \"\"\"\n",
        "    Test face recognition on sample images\n",
        "    \"\"\"\n",
        "    # Setup the recognition system\n",
        "    known_encodings = setup_face_recognition_system()\n",
        "    \n",
        "    if len(known_encodings) == 0:\n",
        "        print(\"‚ùå No known faces available for recognition\")\n",
        "        return\n",
        "    \n",
        "    # Test images\n",
        "    test_images = [\n",
        "        'images/face.jpeg',\n",
        "        'images/person.jpg',\n",
        "        'images/person_1.jpg',\n",
        "        'images/person_2.jpg'\n",
        "    ]\n",
        "    \n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    valid_results = 0\n",
        "    \n",
        "    for i, img_path in enumerate(test_images):\n",
        "        if os.path.exists(img_path):\n",
        "            print(f\"\\nüîç Analyzing {img_path}...\")\n",
        "            \n",
        "            # Perform face recognition\n",
        "            result = recognize_faces_in_image(img_path, known_encodings)\n",
        "            \n",
        "            if result is not None:\n",
        "                # Display results\n",
        "                plt.subplot(2, len(test_images), valid_results + 1)\n",
        "                original_img = cv2.imread(img_path)\n",
        "                plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "                plt.title(f'Original: {Path(img_path).name}')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                plt.subplot(2, len(test_images), valid_results + 1 + len(test_images))\n",
        "                plt.imshow(cv2.cvtColor(result['annotated_image'], cv2.COLOR_BGR2RGB))\n",
        "                plt.title(f'Recognition: {result[\"total_faces\"]} face(s)')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                # Print recognition results\n",
        "                for j, face_result in enumerate(result['results']):\n",
        "                    print(f\"   Face {j+1}: {face_result['name']} (confidence: {face_result['confidence']:.3f})\")\n",
        "                \n",
        "                valid_results += 1\n",
        "            else:\n",
        "                print(f\"   ‚ùå Could not process {img_path}\")\n",
        "        else:\n",
        "            print(f\"‚ùå File not found: {img_path}\")\n",
        "    \n",
        "    if valid_results > 0:\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚ùå No valid results to display\")\n",
        "\n",
        "# Run face recognition test\n",
        "test_face_recognition()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Real-Time Face Recognition\n",
        "\n",
        "Implement real-time face recognition using webcam input.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
