{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 12: Facial Recognition & Landmark Detection (OpenCV DNN + Dlib)\n",
        "\n",
        "## Objective\n",
        "To implement face detection, recognition using face embeddings, and facial landmark detection using OpenCV's DNN module and Dlib. This lab provides a foundation for building real-time face-based systems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What is Facial Recognition?\n",
        "\n",
        "**Description**: Facial recognition involves identifying or verifying a person's identity from an image. It often includes face detection, alignment, embedding extraction, and matching.\n",
        "\n",
        "### Key Components:\n",
        "- **Face Detection**: Locating faces in images\n",
        "- **Face Alignment**: Normalizing face orientation\n",
        "- **Feature Extraction**: Creating face embeddings\n",
        "- **Face Matching**: Comparing embeddings for recognition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "### Required Libraries:\n",
        "- **OpenCV** for face detection and image processing\n",
        "- **Dlib** for landmarks and face embeddings\n",
        "- **face_recognition** wrapper for simplified face encoding and comparison\n",
        "\n",
        "### Installation:\n",
        "```bash\n",
        "pip install opencv-python dlib face_recognition imutils numpy\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Try to import face_recognition and dlib\n",
        "import face_recognition\n",
        "import dlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Face Detection using OpenCV DNN\n",
        "\n",
        "We'll use OpenCV's DNN module with a pre-trained face detection model for robust face detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'MobileNetSSD_deploy.caffemodel')\n",
        "img = cv2.imread('./images/face.jpeg')\n",
        "h, w = img.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "for i in range(detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    if confidence > 0.5:\n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "        (x1, y1, x2, y2) = box.astype(\"int\")\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "cv2.imshow(\"Detected Face\", img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Facial Landmark Detection with Dlib\n",
        "\n",
        "Facial landmarks help identify key points on the face like eyes, nose, mouth, and jaw contours.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m img = cv2.imread(\u001b[33m'\u001b[39m\u001b[33mface.jpg\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m predictor = \u001b[43mdlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshape_predictor_68_face_landmarks.dat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m detector = dlib.get_frontal_face_detector()\n\u001b[32m      7\u001b[39m rects = detector(gray, \u001b[32m1\u001b[39m)\n",
            "\u001b[31mRuntimeError\u001b[39m: Unable to open shape_predictor_68_face_landmarks.dat"
          ]
        }
      ],
      "source": [
        "import dlib\n",
        "from imutils import face_utils\n",
        "img = cv2.imread('face.jpg')\n",
        "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "rects = detector(gray, 1)\n",
        "for rect in rects:\n",
        "    shape = predictor(gray, rect)\n",
        "    shape = face_utils.shape_to_np(shape)\n",
        "    for (x, y) in shape:\n",
        "        cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
        "cv2.imshow(\"Facial Landmarks\", img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test facial landmark detection\n",
        "def test_landmark_detection():\n",
        "    \"\"\"Test facial landmark detection on sample images\"\"\"\n",
        "    \n",
        "    test_images = [\n",
        "        'images/face.jpeg',\n",
        "        'images/person.jpg'\n",
        "    ]\n",
        "    \n",
        "    for img_path in test_images:\n",
        "        if os.path.exists(img_path):\n",
        "            # Load image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                print(f\"\\nðŸ” Processing {img_path}...\")\n",
        "                \n",
        "                # First detect faces\n",
        "                faces, _ = detect_faces_opencv(img, face_detector, detector_type)\n",
        "                print(f\"   Found {len(faces)} face(s)\")\n",
        "                \n",
        "                if len(faces) > 0:\n",
        "                    # Detect landmarks\n",
        "                    landmarks_list, landmarks_img = detect_facial_landmarks(img, faces)\n",
        "                    connections_img = draw_landmark_connections(img, landmarks_list)\n",
        "                    \n",
        "                    # Display results\n",
        "                    plt.figure(figsize=(15, 5))\n",
        "                    \n",
        "                    # Original image\n",
        "                    plt.subplot(1, 3, 1)\n",
        "                    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Original Image')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    # Landmarks points\n",
        "                    plt.subplot(1, 3, 2)\n",
        "                    plt.imshow(cv2.cvtColor(landmarks_img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title(f'Facial Landmarks ({len(landmarks_list)} face(s))')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    # Landmark connections\n",
        "                    plt.subplot(1, 3, 3)\n",
        "                    plt.imshow(cv2.cvtColor(connections_img, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Landmark Connections')\n",
        "                    plt.axis('off')\n",
        "                    \n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    \n",
        "                    # Print landmark details\n",
        "                    for i, landmarks in enumerate(landmarks_list):\n",
        "                        print(f\"   Face {i+1}: {len(landmarks)} landmark groups detected\")\n",
        "                        for feature, points in landmarks.items():\n",
        "                            print(f\"     - {feature}: {len(points)} points\")\n",
        "                else:\n",
        "                    print(\"   No faces detected for landmark analysis\")\n",
        "            else:\n",
        "                print(f\"âŒ Could not load {img_path}\")\n",
        "        else:\n",
        "            print(f\"âŒ File not found: {img_path}\")\n",
        "\n",
        "# Run landmark detection test\n",
        "test_landmark_detection()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Face Recognition using Face Embeddings\n",
        "\n",
        "Face recognition involves creating unique embeddings (feature vectors) for each face and comparing them to identify individuals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_face_encodings(image_path, name):\n",
        "    \"\"\"\n",
        "    Create face encodings for a person from their image\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the person's image\n",
        "        name: Name of the person\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with name and encoding\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        \n",
        "        # Get face encodings\n",
        "        encodings = face_recognition.face_encodings(image)\n",
        "        \n",
        "        if len(encodings) > 0:\n",
        "            print(f\"âœ… Created encoding for {name} from {image_path}\")\n",
        "            return {\n",
        "                'name': name,\n",
        "                'encoding': encodings[0],  # Take first face found\n",
        "                'image_path': image_path\n",
        "            }\n",
        "        else:\n",
        "            print(f\"âŒ No face found in {image_path} for {name}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error creating encoding for {name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def recognize_faces_in_image(image_path, known_encodings, tolerance=0.6):\n",
        "    \"\"\"\n",
        "    Recognize faces in an image by comparing with known encodings\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to image to analyze\n",
        "        known_encodings: List of known face encodings\n",
        "        tolerance: Face matching tolerance (lower = stricter)\n",
        "    \n",
        "    Returns:\n",
        "        Results dictionary with matches and annotated image\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        \n",
        "        # Find face locations and encodings\n",
        "        face_locations = face_recognition.face_locations(image)\n",
        "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
        "        \n",
        "        # Convert to OpenCV format for drawing\n",
        "        cv_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        results = []\n",
        "        \n",
        "        # Compare each found face with known faces\n",
        "        for i, face_encoding in enumerate(face_encodings):\n",
        "            matches = []\n",
        "            distances = []\n",
        "            \n",
        "            for known_face in known_encodings:\n",
        "                if known_face is not None:\n",
        "                    # Compare faces\n",
        "                    match = face_recognition.compare_faces([known_face['encoding']], face_encoding, tolerance=tolerance)\n",
        "                    distance = face_recognition.face_distance([known_face['encoding']], face_encoding)[0]\n",
        "                    \n",
        "                    matches.append(match[0])\n",
        "                    distances.append(distance)\n",
        "            \n",
        "            # Find best match\n",
        "            if any(matches):\n",
        "                best_match_index = distances.index(min(distances))\n",
        "                if matches[best_match_index]:\n",
        "                    name = known_encodings[best_match_index]['name']\n",
        "                    confidence = 1 - distances[best_match_index]\n",
        "                else:\n",
        "                    name = \"Unknown\"\n",
        "                    confidence = 0\n",
        "            else:\n",
        "                name = \"Unknown\"\n",
        "                confidence = 0\n",
        "            \n",
        "            # Draw bounding box and label\n",
        "            top, right, bottom, left = face_locations[i]\n",
        "            \n",
        "            # Choose color based on recognition\n",
        "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "            \n",
        "            # Draw rectangle and label\n",
        "            cv2.rectangle(cv_image, (left, top), (right, bottom), color, 2)\n",
        "            cv2.rectangle(cv_image, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
        "            \n",
        "            # Add text\n",
        "            label = f\"{name} ({confidence:.2f})\" if name != \"Unknown\" else \"Unknown\"\n",
        "            cv2.putText(cv_image, label, (left + 6, bottom - 6), \n",
        "                       cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
        "            \n",
        "            results.append({\n",
        "                'name': name,\n",
        "                'confidence': confidence,\n",
        "                'location': (top, right, bottom, left)\n",
        "            })\n",
        "        \n",
        "        return {\n",
        "            'results': results,\n",
        "            'annotated_image': cv_image,\n",
        "            'total_faces': len(face_locations)\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error in face recognition: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"âœ… Face recognition functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a face recognition system\n",
        "def setup_face_recognition_system():\n",
        "    \"\"\"\n",
        "    Set up a face recognition system with known faces\n",
        "    \"\"\"\n",
        "    print(\"ðŸ”§ Setting up Face Recognition System...\")\n",
        "    \n",
        "    # Define known people (you can add more)\n",
        "    known_people = [\n",
        "        {'name': 'Person_1', 'image': 'images/person_1.jpg'},\n",
        "        {'name': 'Person_2', 'image': 'images/person_2.jpg'},\n",
        "    ]\n",
        "    \n",
        "    # Create encodings for known people\n",
        "    known_encodings = []\n",
        "    \n",
        "    for person in known_people:\n",
        "        if os.path.exists(person['image']):\n",
        "            encoding = create_face_encodings(person['image'], person['name'])\n",
        "            if encoding is not None:\n",
        "                known_encodings.append(encoding)\n",
        "        else:\n",
        "            print(f\"âŒ Image not found: {person['image']}\")\n",
        "    \n",
        "    print(f\"âœ… Face recognition system ready with {len(known_encodings)} known faces\")\n",
        "    return known_encodings\n",
        "\n",
        "def test_face_recognition():\n",
        "    \"\"\"\n",
        "    Test face recognition on sample images\n",
        "    \"\"\"\n",
        "    # Setup the recognition system\n",
        "    known_encodings = setup_face_recognition_system()\n",
        "    \n",
        "    if len(known_encodings) == 0:\n",
        "        print(\"âŒ No known faces available for recognition\")\n",
        "        return\n",
        "    \n",
        "    # Test images\n",
        "    test_images = [\n",
        "        'images/face.jpeg',\n",
        "        'images/person.jpg',\n",
        "        'images/person_1.jpg',\n",
        "        'images/person_2.jpg'\n",
        "    ]\n",
        "    \n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    valid_results = 0\n",
        "    \n",
        "    for i, img_path in enumerate(test_images):\n",
        "        if os.path.exists(img_path):\n",
        "            print(f\"\\nðŸ” Analyzing {img_path}...\")\n",
        "            \n",
        "            # Perform face recognition\n",
        "            result = recognize_faces_in_image(img_path, known_encodings)\n",
        "            \n",
        "            if result is not None:\n",
        "                # Display results\n",
        "                plt.subplot(2, len(test_images), valid_results + 1)\n",
        "                original_img = cv2.imread(img_path)\n",
        "                plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "                plt.title(f'Original: {Path(img_path).name}')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                plt.subplot(2, len(test_images), valid_results + 1 + len(test_images))\n",
        "                plt.imshow(cv2.cvtColor(result['annotated_image'], cv2.COLOR_BGR2RGB))\n",
        "                plt.title(f'Recognition: {result[\"total_faces\"]} face(s)')\n",
        "                plt.axis('off')\n",
        "                \n",
        "                # Print recognition results\n",
        "                for j, face_result in enumerate(result['results']):\n",
        "                    print(f\"   Face {j+1}: {face_result['name']} (confidence: {face_result['confidence']:.3f})\")\n",
        "                \n",
        "                valid_results += 1\n",
        "            else:\n",
        "                print(f\"   âŒ Could not process {img_path}\")\n",
        "        else:\n",
        "            print(f\"âŒ File not found: {img_path}\")\n",
        "    \n",
        "    if valid_results > 0:\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"âŒ No valid results to display\")\n",
        "\n",
        "# Run face recognition test\n",
        "test_face_recognition()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Real-Time Face Recognition\n",
        "\n",
        "Implement real-time face recognition using webcam input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def real_time_face_recognition(known_encodings, duration=30):\n",
        "    \"\"\"\n",
        "    Perform real-time face recognition using webcam\n",
        "    \n",
        "    Args:\n",
        "        known_encodings: List of known face encodings\n",
        "        duration: Duration to run (seconds)\n",
        "    \"\"\"\n",
        "    print(f\"ðŸŽ¥ Starting real-time face recognition for {duration} seconds...\")\n",
        "    print(\"Press 'q' to quit early\")\n",
        "    \n",
        "    # Initialize webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        print(\"âŒ Could not open webcam\")\n",
        "        return\n",
        "    \n",
        "    start_time = cv2.getTickCount()\n",
        "    frame_count = 0\n",
        "    \n",
        "    # Process every nth frame for performance\n",
        "    process_this_frame = True\n",
        "    \n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            \n",
        "            # Resize frame for faster processing\n",
        "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # Only process every other frame to save computation\n",
        "            if process_this_frame:\n",
        "                # Find face locations and encodings\n",
        "                face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "                face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "                \n",
        "                face_names = []\n",
        "                for face_encoding in face_encodings:\n",
        "                    # Compare with known faces\n",
        "                    matches = []\n",
        "                    distances = []\n",
        "                    \n",
        "                    for known_face in known_encodings:\n",
        "                        if known_face is not None:\n",
        "                            match = face_recognition.compare_faces([known_face['encoding']], face_encoding)\n",
        "                            distance = face_recognition.face_distance([known_face['encoding']], face_encoding)[0]\n",
        "                            \n",
        "                            matches.append(match[0])\n",
        "                            distances.append(distance)\n",
        "                    \n",
        "                    # Find best match\n",
        "                    name = \"Unknown\"\n",
        "                    if len(distances) > 0 and any(matches):\n",
        "                        best_match_index = distances.index(min(distances))\n",
        "                        if matches[best_match_index]:\n",
        "                            name = known_encodings[best_match_index]['name']\n",
        "                    \n",
        "                    face_names.append(name)\n",
        "            \n",
        "            process_this_frame = not process_this_frame\n",
        "            \n",
        "            # Display results on full-size frame\n",
        "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "                # Scale back up face locations\n",
        "                top *= 4\n",
        "                right *= 4\n",
        "                bottom *= 4\n",
        "                left *= 4\n",
        "                \n",
        "                # Choose color\n",
        "                color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "                \n",
        "                # Draw rectangle\n",
        "                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
        "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
        "                \n",
        "                # Add label\n",
        "                cv2.putText(frame, name, (left + 6, bottom - 6), \n",
        "                           cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
        "            \n",
        "            # Add frame counter and instructions\n",
        "            cv2.putText(frame, f'Frame: {frame_count}', (10, 30), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "            cv2.putText(frame, 'Press Q to quit', (10, frame.shape[0] - 10), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "            \n",
        "            # Display frame\n",
        "            cv2.imshow('Real-Time Face Recognition', frame)\n",
        "            \n",
        "            frame_count += 1\n",
        "            \n",
        "            # Check for quit or time limit\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                print(\"\\nðŸ‘‹ Quit requested\")\n",
        "                break\n",
        "                \n",
        "            # Check time limit\n",
        "            elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
        "            if elapsed_time > duration:\n",
        "                print(f\"\\nâ° Time limit reached ({duration}s)\")\n",
        "                break\n",
        "                \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nâš ï¸ Interrupted by user\")\n",
        "    \n",
        "    finally:\n",
        "        # Cleanup\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        \n",
        "        # Calculate FPS\n",
        "        total_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
        "        fps = frame_count / total_time if total_time > 0 else 0\n",
        "        \n",
        "        print(f\"\\nðŸ“Š Session Summary:\")\n",
        "        print(f\"   Total frames: {frame_count}\")\n",
        "        print(f\"   Duration: {total_time:.1f}s\")\n",
        "        print(f\"   Average FPS: {fps:.1f}\")\n",
        "\n",
        "print(\"âœ… Real-time face recognition function defined\")\n",
        "print(\"\\nðŸ’¡ To start real-time recognition, run:\")\n",
        "print(\"known_encodings = setup_face_recognition_system()\")\n",
        "print(\"real_time_face_recognition(known_encodings, duration=30)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "### What We Implemented:\n",
        "- **OpenCV DNN** provides fast face detection\n",
        "- **Dlib** enables precise landmark localization  \n",
        "- **Face embeddings** are robust descriptors for recognition\n",
        "- **Real-time systems** can be built using webcam + pre-trained encoders\n",
        "\n",
        "### Key Features:\n",
        "- Face detection using Haar cascades\n",
        "- Facial landmark detection with 68 key points\n",
        "- Face recognition using embeddings\n",
        "- Real-time processing capabilities\n",
        "\n",
        "### Applications:\n",
        "- Security systems\n",
        "- Attendance tracking\n",
        "- Photo organization\n",
        "- Augmented reality filters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Suggested Exercises\n",
        "\n",
        "1. **Build a multi-face recognition system**\n",
        "   - Add more known faces to the database\n",
        "   - Test with group photos\n",
        "\n",
        "2. **Record embedding vectors for 5 individuals and match against a test feed**\n",
        "   - Create a face database with multiple photos per person\n",
        "   - Test recognition accuracy\n",
        "\n",
        "3. **Display landmarks on live video**\n",
        "   - Real-time landmark detection\n",
        "   - Face filter applications\n",
        "\n",
        "4. **Extend the pipeline to recognize expressions using landmarks**\n",
        "   - Analyze facial expressions\n",
        "   - Emotion detection system\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
