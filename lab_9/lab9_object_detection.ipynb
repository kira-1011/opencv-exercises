{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 9: Object Detection with OpenCV (Python)\n",
        "\n",
        "## Objective\n",
        "To learn and implement classical object detection techniques in OpenCV using Haar Cascades and HOG + SVM. This lab includes face and pedestrian detection from images and video streams.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What is Object Detection?\n",
        "\n",
        "**Description**: Object detection is the task of locating and classifying objects within an image. It outputs bounding boxes around objects of interest.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Haar Cascade Classifiers\n",
        "\n",
        "**Description**: Haar cascades use features trained with AdaBoost and cascade classifiers to detect objects quickly in real-time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Face Detection with Haar Cascades\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "img = cv2.imread('images/face_sample.jpeg')\n",
        "\n",
        "# Resize image to fit screen better (keep aspect ratio)\n",
        "height, width = img.shape[:2]\n",
        "if width > 800 or height > 600:\n",
        "    scale = min(800/width, 600/height)\n",
        "    new_width = int(width * scale)\n",
        "    new_height = int(height * scale)\n",
        "    img = cv2.resize(img, (new_width, new_height))\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "# Create resizable window\n",
        "cv2.namedWindow('Detected Faces', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Detected Faces', 800, 600)\n",
        "cv2.imshow('Detected Faces', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Output Description: Draws rectangles around detected faces using pre-trained Haar cascades.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. HOG + SVM Detector\n",
        "\n",
        "**Description**: HOG (Histogram of Oriented Gradients) captures edge and gradient structure. Paired with SVM, it's effective for detecting pedestrians.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Pedestrian Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "img = cv2.imread('images/pedestrian.jpg')\n",
        "\n",
        "# Resize image to manageable size for display\n",
        "height, width = img.shape[:2]\n",
        "if width > 800 or height > 600:\n",
        "    scale = min(800/width, 600/height)\n",
        "    new_width = int(width * scale)\n",
        "    new_height = int(height * scale)\n",
        "    img = cv2.resize(img, (new_width, new_height))\n",
        "\n",
        "(rects, weights) = hog.detectMultiScale(img, winStride=(8,8), padding=(8,8), scale=1.05)\n",
        "\n",
        "for (x, y, w, h) in rects:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "# Create resizable window\n",
        "cv2.namedWindow('Pedestrian Detection', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Pedestrian Detection', 800, 600)\n",
        "cv2.imshow('Pedestrian Detection', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Output Description: Draws green rectangles around pedestrians in the image using HOG + SVM detector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Real-Time Detection with Webcam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Create resizable window for webcam\n",
        "cv2.namedWindow('Real-Time Face Detection', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Real-Time Face Detection', 800, 600)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "    \n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    \n",
        "    cv2.imshow('Real-Time Face Detection', frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Output Description: Performs live face detection from the webcam and displays it in real-time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n",
        "\n",
        "â€¢ **Haar Cascades** are fast but sensitive to lighting and scale.\n",
        "â€¢ **HOG + SVM** is more robust and well-suited for pedestrian detection.\n",
        "â€¢ Both methods work without deep learning and run in real time on CPUs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Suggested Exercises Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Detect eyes or smiles using haarcascade_eye.xml or haarcascade_smile.xml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 1: Eye and smile detection completed!\n",
            "Blue = Face, Green = Eyes, Red = Smile\n"
          ]
        }
      ],
      "source": [
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
        "\n",
        "img = cv2.imread('images/face_smile.jpg')\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Detect faces first\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    \n",
        "    # Region of interest within face\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    \n",
        "    # Detect eyes\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
        "    for (ex, ey, ew, eh) in eyes:\n",
        "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "    \n",
        "    # Detect smiles\n",
        "    smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
        "    for (sx, sy, sw, sh) in smiles:\n",
        "        cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
        "\n",
        "cv2.namedWindow('Face Features Detection', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Face Features Detection', 600, 900)\n",
        "cv2.imshow('Face Features Detection', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Exercise 1: Eye and smile detection completed!\")\n",
        "print(\"Blue = Face, Green = Eyes, Red = Smile\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Replace webcam input with video file and detect people frame-by-frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing video and saving detection results...\n",
            "Output will be saved as 'videos/people_detected.mp4'\n",
            "âœ… Video processing complete!\n",
            "ðŸ“¹ Output saved: videos/people_detected.mp4\n",
            "ðŸ“Š Statistics:\n",
            "   â€¢ Total frames: 596\n",
            "   â€¢ Total detections: 139\n",
            "   â€¢ Average detections per frame: 0.23\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture('videos/people.mp4')\n",
        "\n",
        "# Get video properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Set up video writer to save the output\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('videos/people_detected.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "frame_count = 0\n",
        "detection_count = 0\n",
        "\n",
        "print(\"Processing video and saving detection results...\")\n",
        "print(\"Output will be saved as 'videos/people_detected.mp4'\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "        \n",
        "    frame_count += 1\n",
        "    \n",
        "    # Detect pedestrians in current frame\n",
        "    (rects, weights) = hog.detectMultiScale(frame, winStride=(8,8), padding=(8,8), scale=1.05)\n",
        "    \n",
        "    current_detections = len(rects)\n",
        "    detection_count += current_detections\n",
        "    \n",
        "    # Draw rectangles around detected pedestrians\n",
        "    for (x, y, w, h) in rects:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "        cv2.putText(frame, 'Person', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "    \n",
        "    # Add frame info\n",
        "    cv2.putText(frame, f'Frame: {frame_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "    cv2.putText(frame, f'People: {current_detections}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "    \n",
        "    # Write the frame to output video\n",
        "    out.write(frame)\n",
        "    \n",
        "    # Optional: Display while processing (comment out for faster processing)\n",
        "    cv2.imshow('Processing Video...', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"âœ… Video processing complete!\")\n",
        "print(f\"ðŸ“¹ Output saved: videos/people_detected.mp4\")\n",
        "print(f\"ðŸ“Š Statistics:\")\n",
        "print(f\"   â€¢ Total frames: {frame_count}\")\n",
        "print(f\"   â€¢ Total detections: {detection_count}\")\n",
        "print(f\"   â€¢ Average detections per frame: {detection_count/frame_count:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 3: Tune the HOG detector parameters (e.g., scale, winStride) for different performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "High Precision: 8 pedestrians detected\n",
            "Balanced: 4 pedestrians detected\n",
            "Fast Detection: 1 pedestrians detected\n",
            "Exercise 3: Parameter tuning completed!\n"
          ]
        }
      ],
      "source": [
        "img = cv2.imread('images/pedestrian.jpg')\n",
        "\n",
        "# Resize for display\n",
        "height, width = img.shape[:2]\n",
        "if width > 800 or height > 600:\n",
        "    scale = min(800/width, 600/height)\n",
        "    new_width = int(width * scale)\n",
        "    new_height = int(height * scale)\n",
        "    img = cv2.resize(img, (new_width, new_height))\n",
        "\n",
        "# Test different parameter combinations\n",
        "param_configs = [\n",
        "    {'winStride': (4, 4), 'padding': (8, 8), 'scale': 1.02, 'name': 'High Precision'},\n",
        "    {'winStride': (8, 8), 'padding': (8, 8), 'scale': 1.05, 'name': 'Balanced'},\n",
        "    {'winStride': (16, 16), 'padding': (16, 16), 'scale': 1.1, 'name': 'Fast Detection'}\n",
        "]\n",
        "\n",
        "for i, config in enumerate(param_configs):\n",
        "    test_img = img.copy()\n",
        "    \n",
        "    # Detect with current parameters\n",
        "    (rects, weights) = hog.detectMultiScale(\n",
        "        test_img, \n",
        "        winStride=config['winStride'], \n",
        "        padding=config['padding'], \n",
        "        scale=config['scale']\n",
        "    )\n",
        "    \n",
        "    # Draw rectangles\n",
        "    for (x, y, w, h) in rects:\n",
        "        cv2.rectangle(test_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    \n",
        "    # Add parameter info\n",
        "    cv2.putText(test_img, f\"{config['name']}: {len(rects)} detections\", \n",
        "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "    \n",
        "    cv2.namedWindow(f'HOG Tuning - {config[\"name\"]}', cv2.WINDOW_NORMAL)\n",
        "    cv2.resizeWindow(f'HOG Tuning - {config[\"name\"]}', 800, 600)\n",
        "    cv2.imshow(f'HOG Tuning - {config[\"name\"]}', test_img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    print(f\"{config['name']}: {len(rects)} pedestrians detected\")\n",
        "\n",
        "print(\"Exercise 3: Parameter tuning completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Combine face and body detection into a single pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 4: Combined detection completed!\n",
            "Detected 0 faces and 4 pedestrians\n",
            "Blue boxes = Faces, Green boxes = Pedestrians\n"
          ]
        }
      ],
      "source": [
        "img = cv2.imread('images/pedestrian.jpg')\n",
        "\n",
        "# Resize for display\n",
        "height, width = img.shape[:2]\n",
        "if width > 800 or height > 600:\n",
        "    scale = min(800/width, 600/height)\n",
        "    new_width = int(width * scale)\n",
        "    new_height = int(height * scale)\n",
        "    img = cv2.resize(img, (new_width, new_height))\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Face detection with Haar cascades\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    cv2.putText(img, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "# Pedestrian detection with HOG+SVM\n",
        "(rects, weights) = hog.detectMultiScale(img, winStride=(8,8), padding=(8,8), scale=1.05)\n",
        "for (x, y, w, h) in rects:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    cv2.putText(img, 'Person', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "cv2.namedWindow('Combined Detection', cv2.WINDOW_NORMAL)\n",
        "cv2.resizeWindow('Combined Detection', 800, 600)\n",
        "cv2.imshow('Combined Detection', img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Exercise 4: Combined detection completed!\")\n",
        "print(f\"Detected {len(faces)} faces and {len(rects)} pedestrians\")\n",
        "print(\"Blue boxes = Faces, Green boxes = Pedestrians\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
